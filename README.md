# GPT
OpenAI GPT, Generative Pre-Training

OpenAI GPT model was proposed in **Improving Language Understanding by Generative Pre-Training** by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever. Itâ€™s a causal (unidirectional) transformer pre-trained using language modeling on a large corpus will long range dependencies, the Toronto Book Corpus.

