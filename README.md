# GPT
OpenAI GPT, Generative Pre-Training

OpenAI GPT model was proposed in **Improving Language Understanding by Generative Pre-Training** by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever. Itâ€™s a causal (unidirectional) transformer pre-trained using language modeling on a large corpus will long range dependencies, the Toronto Book Corpus.


## How to see ðŸ˜²

**Just type the '.' on your keyboard now!!**, 

![Inkedkeyb_LI](https://user-images.githubusercontent.com/46081500/157036957-1af65660-cf8d-4f03-891d-4d951d88d861.jpg)


for watching the directory (codes) on Visual Studio Code -Github
